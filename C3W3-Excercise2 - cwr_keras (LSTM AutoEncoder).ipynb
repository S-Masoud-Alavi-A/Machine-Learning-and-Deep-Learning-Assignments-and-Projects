{"cells": [{"metadata": {}, "cell_type": "markdown", "source": "# Preparation steps before running this notebook\n1. Run cwr_etl.ipynb first\n2. Paste the IBM COS (Cloud Object Store) configuration below, either bei following the tutorial mentioned below or by taking the already existing config from cwr_etl.ipynb"}, {"metadata": {}, "cell_type": "code", "source": "# In order to obtain the correct values for \"credentias\", \"bucket_name\" and \"endpoint\" \n# please follow the tutorial at https://github.com/IBM/skillsnetwork/wiki/Cloud-Object-Storage-Setup\n# The following Credentials created by my own\n\n#credentials = { # your credentials go here}\ncredentials={\n  \"apikey\": \"eiyCrlzvyVzQloSlM9IAMMeIbBYVWEfnCtdoC9uJ5qH3\",\n  \"cos_hmac_keys\": {\n    \"access_key_id\": \"2fc45cbac4a04e89877822a08ccfd761\",\n    \"secret_access_key\": \"fd876a91354f575d742141a4ec6029a024d698a934b83f42\"\n  },\n  \"endpoints\": \"https://control.cloud-object-storage.cloud.ibm.com/v2/endpoints\",\n  \"iam_apikey_description\": \"Auto-generated for key 2fc45cba-c4a0-4e89-8778-22a08ccfd761\",\n  \"iam_apikey_name\": \"Service credentials-1\",\n  \"iam_role_crn\": \"crn:v1:bluemix:public:iam::::serviceRole:Writer\",\n  \"iam_serviceid_crn\": \"crn:v1:bluemix:public:iam-identity::a/c781194517d84693ab87a123af03cd17::serviceid:ServiceId-9d24692b-2f05-4ec0-bd51-c7e8231a0c98\",\n  \"resource_instance_id\": \"crn:v1:bluemix:public:cloud-object-storage:global:a/c781194517d84693ab87a123af03cd17:8dba9f55-d336-4721-99b9-54d686ce6f1a::\"\n}\n\n\nbucket_name = \"cloud-object-storage-cos-standard-ub4\" # your bucket name goes here\nendpoint = \"https://s3.eu-de.cloud-object-storage.appdomain.cloud\" # your endpoint goes here", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "import base64\nfrom ibm_botocore.client import Config\nimport ibm_boto3\nimport time\n\n\n\n\n# Create client \nclient = ibm_boto3.client(\n    's3',\n    aws_access_key_id = credentials[\"cos_hmac_keys\"]['access_key_id'],\n    aws_secret_access_key = credentials[\"cos_hmac_keys\"][\"secret_access_key\"],\n    endpoint_url=endpoint\n)\n\n\n\nclient.download_file(bucket_name,'result_healthy_pandas.csv', 'result_healthy_pandas.csv')\nclient.download_file(bucket_name,'result_faulty_pandas.csv', 'result_faulty_pandas.csv')", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "import pandas as pd\ndf_healthy = pd.read_csv('result_healthy_pandas.csv', engine='python', header=None)\ndf_healthy.head()", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "df_healthy.loc[df_healthy[1] == 100]", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "df_faulty = pd.read_csv('result_faulty_pandas.csv', engine='python', header=None)\ndf_faulty.head()", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "df_faulty.loc[df_healthy[1] == 100]", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "import numpy as np\nfrom numpy import concatenate\nfrom matplotlib import pyplot\nfrom pandas import read_csv\nfrom pandas import DataFrame\nfrom pandas import concat\nimport sklearn\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.metrics import mean_squared_error\nfrom keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras.layers import LSTM\nfrom keras.callbacks import Callback\nfrom keras.models import Sequential\nfrom keras.layers import LSTM, Dense, Activation\nimport matplotlib.pyplot as plt\nfrom mpl_toolkits.mplot3d import Axes3D\nimport time\n%matplotlib inline", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "def get_recording(df,file_id):\n    return np.array(df.sort_values(by=0, ascending=True).loc[df[1] == file_id].drop(0,1).drop(1,1))\n", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "import numpy as np\nhealthy_sample = get_recording(df_healthy,100)\nfaulty_sample = get_recording(df_faulty,125)", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "fig, ax = plt.subplots(num=None, figsize=(14, 6), dpi=80, facecolor='w', edgecolor='k')\nsize = len(healthy_sample)\nax.plot(range(0,size), healthy_sample[:,0], '-', color='red', animated = True, linewidth=1)\nax.plot(range(0,size), healthy_sample[:,1], '-', color='blue', animated = True, linewidth=1)", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "fig, ax = plt.subplots(num=None, figsize=(14, 6), dpi=80, facecolor='w', edgecolor='k')\nsize = len(faulty_sample)\nax.plot(range(0,size), faulty_sample[:,1], '-', color='red', animated = True, linewidth=1)\nax.plot(range(0,size), faulty_sample[:,0], '-', color='blue', animated = True, linewidth=1)", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "fig, ax = plt.subplots(num=None, figsize=(14, 6), dpi=80, facecolor='w', edgecolor='k')\nax.plot(range(0,500), healthy_sample[:500,0], '-', color='red', animated = True, linewidth=1)\nax.plot(range(0,500), healthy_sample[:500,1], '-', color='blue', animated = True, linewidth=1)", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "fig, ax = plt.subplots(num=None, figsize=(14, 6), dpi=80, facecolor='w', edgecolor='k')\nax.plot(range(0,500), faulty_sample[:500,0], '-', color='red', animated = True, linewidth=1)\nax.plot(range(0,500), faulty_sample[:500,1], '-', color='blue', animated = True, linewidth=1)", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "class LossHistory(Callback):\n    def on_train_begin(self, logs={}):\n        self.losses = []\n\n    def on_batch_end(self, batch, logs={}):\n        self.losses.append(logs.get('loss'))", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "timesteps = 100\ndim = 2\nlossHistory = LossHistory()\n# design network\n\nmodel = Sequential()\nmodel.add(LSTM(50,input_shape=(timesteps,dim),return_sequences=True))\nmodel.add(Dense(2))\nmodel.compile(loss='mae', optimizer='adam')\n\ndef train(data):\n    model.fit(data, data, epochs=20, batch_size=72, validation_data=(data, data), verbose=1, shuffle=False,callbacks=[lossHistory])\n\ndef score(data):\n    yhat =  model.predict(data)\n    return yhat", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "#some learners constantly reported 502 errors in Watson Studio. \n#This is due to the limited resources in the free tier and the heavy resource consumption of Keras.\n#This is a workaround to limit resource consumption\n\nfrom keras import backend as K\n\nK.set_session(K.tf.Session(config=K.tf.ConfigProto(intra_op_parallelism_threads=1, inter_op_parallelism_threads=1)))\n", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "def create_trimmed_recording(df,file_id):\n    recording = get_recording(df,file_id) \n    samples = len(recording)\n    trim = samples % 100\n    recording_trimmed = recording[:samples-trim]\n    recording_trimmed.shape = (int((samples-trim)/timesteps),timesteps,dim)\n    return recording_trimmed\n", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "#pd.unique()\n#df_healthy.drop(0,1).drop(2,1).drop(3,1)\npd.unique(df_healthy.iloc[:,1])", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "file_ids = pd.unique(df_healthy.iloc[:,1])\nstart = time.time()\nfor file_id in file_ids:\n    recording_trimmed = create_trimmed_recording(df_healthy,file_id)\n    print(\"Staring training on %s\" % (file_id))\n    train(recording_trimmed)\n    print(\"Finished training on %s after %s seconds\" % (file_id,time.time()-start))\n\nprint(\"Finished job on after %s seconds\" % (time.time()-start))\nhealthy_losses = lossHistory.losses\n", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "fig, ax = plt.subplots(num=None, figsize=(14, 6), dpi=80, facecolor='w', edgecolor='k')\nsize = len(healthy_losses)\nplt.ylim(0,0.008)\nax.plot(range(0,size), healthy_losses, '-', color='blue', animated = True, linewidth=1)", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "#file_ids = spark.sql('select distinct _c1 from df_healhty').rdd.map(lambda row : row._c1).collect()\nstart = time.time()\nfor file_id in [105]:\n    recording_trimmed = create_trimmed_recording(df_faulty,file_id)\n    print(\"Staring training on %s\" % (file_id))\n    train(recording_trimmed)\n    print(\"Finished training on %s after %s seconds\" % (file_id,time.time()-start))\n\nprint(\"Finished job on after %s seconds\" % (time.time()-start))\nfaulty_losses = lossHistory.losses", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "file_ids = pd.unique(df_faulty.iloc[:,1])\nstart = time.time()\nfor file_id in file_ids:\n    recording_trimmed = create_trimmed_recording(df_faulty,file_id)\n    print(\"Staring training on %s\" % (file_id))\n    train(recording_trimmed)\n    print(\"Finished training on %s after %s seconds\" % (file_id,time.time()-start))\n\nprint(\"Finished job on after %s seconds\" % (time.time()-start))\nfaulty_losses = lossHistory.losses\n", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "fig, ax = plt.subplots(num=None, figsize=(14, 6), dpi=80, facecolor='w', edgecolor='k')\nsize = len(healthy_losses+faulty_losses)\nplt.ylim(0,0.008)\nax.plot(range(0,size), healthy_losses+faulty_losses, '-', color='blue', animated = True, linewidth=1)", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "", "execution_count": null, "outputs": []}], "metadata": {"kernelspec": {"name": "python36", "display_name": "Python 3.6 with Spark", "language": "python3"}, "language_info": {"mimetype": "text/x-python", "nbconvert_exporter": "python", "name": "python", "pygments_lexer": "ipython3", "version": "3.6.8", "file_extension": ".py", "codemirror_mode": {"version": 3, "name": "ipython"}}}, "nbformat": 4, "nbformat_minor": 1}