{"cells": [{"metadata": {}, "cell_type": "code", "source": "# creted, coppied and pasted by my own using video lectures\n\nimport ibmos2spark\n\n# @hidden_cell\nCredentials = {'endpoint':'https://s3-api.us-geo.objectstorage.service.networklayer.com',\n                'api_key': 'iTfSE_YVE6zqnxjdloK0E37R2aVYY4dFhXFFC1jE1AcJ',\n                'sevice_id':'iam-ServiceId-d4b06e46-293a-4417-b76c-2f16076a9353'\n                'iam_service_endpoint':'https://iam.ng.bluemix.net/oidc/token'}\n                \nconfiguration_name = 'os_b0f1407510994fd1b793b85137baafb8_configs'\ncos=ibmos2spark.CloudObjectStorage(sc, credentials, configuration_name, 'bluemix_cos')\n\nfrom pyspark.sql import SparkSession\nspark = SparkSession.builder.getOrCreate()\n#the last two instructions have been changed according the second C2W2 course video lecture.\ndf_data_1 = spark.read.parquet(cos.url('hmp.parquet', 'courseraml-donotdelete-pr-qve0ttzezdeodc'))\ndf_data_1.show()", "execution_count": 1, "outputs": [{"output_type": "stream", "text": "Waiting for a Spark session to start...\nSpark Initialization Done! ApplicationId = app-20200902150215-0001\nKERNEL_ID = 5040e671-ec60-4de8-9837-16335897ab01\n", "name": "stdout"}, {"output_type": "error", "ename": "SyntaxError", "evalue": "invalid syntax (<ipython-input-1-b4290f5f1e22>, line 9)", "traceback": ["\u001b[0;36m  File \u001b[0;32m\"<ipython-input-1-b4290f5f1e22>\"\u001b[0;36m, line \u001b[0;32m9\u001b[0m\n\u001b[0;31m    'iam_service_endpoint':'https://iam.ng.bluemix.net/oidc/token'}\u001b[0m\n\u001b[0m                          ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"]}]}, {"metadata": {}, "cell_type": "code", "source": "##inserted and creted by my own using video lectures\n\n#import ibmos2spark\n## @hidden_cell\n#credentials = {\n#    'endpoint': 'https://s3-api.us-geo.objectstorage.service.networklayer.com',\n#    'service_id': 'iam-ServiceId-424b68aa-0a29-4afa-b32a-11948b9a88b1',\n#    'iam_service_endpoint': 'https://iam.cloud.ibm.com/oidc/token',\n#    'api_key': '7yLR96nAT9xLrI-IYfbCmZv6Va3R2wG22cLz2kcSvjEV'\n#}\n\n#configuration_name = 'os_8dba9f55d336472199b954d686ce6f1a_configs'\n#cos = ibmos2spark.CloudObjectStorage(sc, credentials, configuration_name, 'bluemix_cos')\n\n#from pyspark.sql import SparkSession\n#spark = SparkSession.builder.getOrCreate()\n\n## I should note that, the last two instruction have been changed automatically by insertion process and the following commend inserted insted.\n\n## Since JSON data can be semi-structured and contain additional metadata, it is possible that you might face issues with the DataFrame layout.\n## Please read the documentation of 'SparkSession.read()' to learn more about the possibilities to adjust the data loading.\n## PySpark documentation: http://spark.apache.org/docs/2.0.2/api/python/pyspark.sql.html#pyspark.sql.DataFrameReader.json\n\n## df_data_2 = spark.read.json(cos.url('floorsensordata2604.json', 'courseadvanceddatascience-donotdelete-pr-h2avgv4jgwmwxi'))\n## df_data_2.take(5)", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "df=df_data_1", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "data.createOrReplaceTempView('df')", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "df_energy = spark.sql(\"\"\"\nselect sqrt(sum(x*x)+sum(y*y)+sum(z*z)) as label, class from df group by class\n\"\"\")#.show()\n\ndf_energy.createOrReplaceTempView('df_energy')", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "df_join = spark.sql(\"\"\"\nselect * from df linear join df_energy on df.class = df_energy.class\n\n\"\"\")\ndf_join.show()", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "from pyspark.ml.feature import VectorAssembler\nfrom pyspark.ml.feature import Normalizer\n\nvectorAssembler = VectorAssembler(inputCols=[\"x\",\"y\",\"Z\"], outputCol=\"features\")\nnormalizer = Normalizer(inputCol=\"features\", outputCol=\"features_norm\", p=1.0)", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "from pyspark.ml.regression import LinearRegression", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "lr = LinearRegression(maxIter=10, regParam=0.3, elasticNetParam=0.8)", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "from pyspark.ml import Pipeline", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "pipeline = Pipeline(stages=[vectorAssembler, normalizer, lr])", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "model = pipeline.fit(df_join)", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "predictions= model.transform(df_join)", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "model.stages[2].summary.r2", "execution_count": null, "outputs": []}], "metadata": {"kernelspec": {"name": "python36", "display_name": "Python 3.6 with Spark", "language": "python3"}, "language_info": {"mimetype": "text/x-python", "nbconvert_exporter": "python", "name": "python", "pygments_lexer": "ipython3", "version": "3.6.8", "file_extension": ".py", "codemirror_mode": {"version": 3, "name": "ipython"}}}, "nbformat": 4, "nbformat_minor": 1}