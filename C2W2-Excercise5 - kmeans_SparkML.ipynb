{"cells": [{"metadata": {}, "cell_type": "markdown", "source": "This notebook is designed to run in a IBM Watson Studio default runtime (NOT the Watson Studio Apache Spark Runtime as the default runtime with 1 vCPU). Therefore,  Apache Spark is installed in local mode (for test purposes only). We wont use it in production.\n\nIn case of facing issues, the following two documents could help me:\n\nhttps://github.com/IBM/skillsnetwork/wiki/Environment-Setup\n\nhttps://github.com/IBM/skillsnetwork/wiki/FAQ\n\nThen, I can ask for help here:\n\nhttps://coursera.org/learn/machine-learning-big-data-apache-spark/discussions/all\n\nBefore asking a question, I should  make sure to follow the guidelines:\n\nhttps://github.com/IBM/skillsnetwork/wiki/FAQ#im-feeling-lost-and-confused-please-help-me\n\n\nIf running outside Watson Studio, this should work as well. In case I am running in an Apache Spark context outside Watson Studio, I must remove the Apache Spark setup in the first notebook cells."}, {"metadata": {}, "cell_type": "code", "source": "from IPython.display import Markdown, display\ndef printmd(string):\n    display(Markdown('# <span style=\"color:red\">'+string+'</span>'))\n\n\nif ('sc' in locals() or 'sc' in globals()):\n    printmd('<<<<<!!!!! It seems that you are running in a IBM Watson Studio Apache Spark Notebook. Please run it in an IBM Watson Studio Default Runtime (without Apache Spark) !!!!!>>>>>')\n", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "!pip install pyspark==2.4.5", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "try:\n    from pyspark import SparkContext, SparkConf\n    from pyspark.sql import SparkSession\nexcept ImportError as e:\n    printmd('<<<<<!!!!! Please restart your kernel after installing Apache Spark !!!!!>>>>>')", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "sc = SparkContext.getOrCreate(SparkConf().setMaster(\"local[*]\"))\n\nspark = SparkSession \\\n    .builder \\\n    .getOrCreate()", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "In case you want to learn how ETL is done, please run the following notebook first and update the file name below accordingly\n\nhttps://github.com/IBM/coursera/blob/master/coursera_ml/a2_w1_s3_ETL.ipynb"}, {"metadata": {}, "cell_type": "code", "source": "# delete files from previous runs\n!rm -f hmp.parquet*\n\n# download the file containing the data in PARQUET format\n!wget https://github.com/IBM/coursera/raw/master/hmp.parquet\n    \n# create a dataframe out of it\ndf = spark.read.parquet('hmp.parquet')\n\n# register a corresponding query table\ndf.createOrReplaceTempView('df')", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "from pyspark.ml.feature import VectorAssembler\n\nvectorAssembler = VectorAssembler(inputCols=[\"x\",\"y\",\"z\"],\n                                  outputCol=\"features\")", "execution_count": 2, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "from pyspark.ml.clustering import KMeans\n\nkmeans = KMeans().setK(13).setSeed(1)", "execution_count": 8, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "\nfrom pyspark.ml import Pipeline\npipeline = Pipeline(stages=[vectorAssembler, kmeans])\n", "execution_count": 9, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "df.createOrReplaceTempView('df')\ndf = spark.sql(\"select * from df where class in ('Brush_teeth','Climb_stairs')\")", "execution_count": 20, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "model = pipeline.fit(df)", "execution_count": 21, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "wssse = model.stages[1].computeCost(vectorAssembler.transform(df))\nprint(\"Within Set Sum of Squared Errors = \" + str(wssse))", "execution_count": 22, "outputs": [{"name": "stdout", "output_type": "stream", "text": "Within Set Sum of Squared Errors = 2608592.45879\n"}]}, {"metadata": {}, "cell_type": "code", "source": "", "execution_count": null, "outputs": []}], "metadata": {"kernelspec": {"name": "python3", "display_name": "Python 3.6", "language": "python"}, "language_info": {"name": "python", "version": "3.6.9", "mimetype": "text/x-python", "codemirror_mode": {"name": "ipython", "version": 3}, "pygments_lexer": "ipython3", "nbconvert_exporter": "python", "file_extension": ".py"}}, "nbformat": 4, "nbformat_minor": 4}
